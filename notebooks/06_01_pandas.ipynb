{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# This is the notebook for the python pandas dataframe course\n",
    "### The idea of this notebook is to show the power of working with pandas dataframes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Motivation\n",
    "\n",
    "We usually work with tabular data\n",
    "\n",
    "We should not handle them with bash commands like: for, split, grep, awk, etc...\n",
    "\n",
    "And **pandas is a very nice tool** to handle this kind of data.\n",
    "\n",
    "**Welcome to Pandas!**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Definition of pandas:\n",
    "\n",
    "Python package providing fast, flexible, and expressive data structures designed to make working with “relational” or “labeled” data both easy and intuitive. \n",
    "\n",
    "It aims to be the fundamental high-level building block for doing practical, real world data analysis in Python. \n",
    "\n",
    "Additionally, it has the broader goal of becoming the most powerful and flexible open source data analysis / manipulation tool available in any language.\n",
    "\n",
    "More information about pandas: <http://pandas.pydata.org/pandas-docs/stable/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Contents of the course:\n",
    "\n",
    "- [Know your data](#know):\n",
    "  - Dimensionality: Series or DataFrame\n",
    "  - Index\n",
    "  - Some examples\n",
    "  - [Exercise 1](#exercise1): Selecting pandas structure\n",
    "\n",
    "\n",
    "- [I/O](#io):\n",
    "   - Reading: CSV, FITS, SQL\n",
    "   - Writing: CSV\n",
    "   - Advanced example: Reading and writing CSV files by chunks\n",
    "\n",
    "\n",
    "- [Selecting and slicing](#selecting):\n",
    "    - *loc.* & *iloc.*\n",
    "    - Advanced example: Estimate a galaxy property for a subset of galaxies using boolean conditions\n",
    "    - [Exercise 2](#exercise2): Estimate another galaxy property\n",
    "\n",
    "\n",
    "- [Merge, join, and concatenate](#merging):\n",
    "    - [Exercise 3](#exercise3): Generate a random catalog using the *concat* method\n",
    "    - Example: Merging dataframes using the *merge* method\n",
    "\n",
    "\n",
    "- [More functions](#functions):\n",
    "    - Loop a dataframe (itertuples and iterows)\n",
    "    - Sort\n",
    "    - Sample\n",
    "    - Reshape: pivot, stack, unstack, etc.\n",
    "\n",
    "\n",
    "\n",
    "- [Caveats and technicalities](#caveats):\n",
    "    - Floating point limitations\n",
    "    - .values\n",
    "    - FITS chunks\n",
    "    - View or copy\n",
    "    - Wrong input example"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Some useful information\n",
    "\n",
    "- Ten minutes to pandas:\n",
    "\n",
    "<https://pandas.pydata.org/pandas-docs/stable/10min.html>\n",
    "\n",
    "- Pandas cookbook:\n",
    "\n",
    "<https://pandas.pydata.org/pandas-docs/stable/cookbook.html>\n",
    "\n",
    "- Nice pandas course:\n",
    "\n",
    "<https://www.datacamp.com/community/tutorials/pandas-tutorial-dataframe-python#gs.=B6Dr74>\n",
    "\n",
    "- Multidimensional dataframes, xarray: \n",
    "\n",
    "<http://xarray.pydata.org/en/stable/>\n",
    "\n",
    "- Tips & Tricks\n",
    "\n",
    "<https://www.dataquest.io/blog/jupyter-notebook-tips-tricks-shortcuts/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=know></a>\n",
    "## Know your data\n",
    "\n",
    "Very important to (perfectly) know your data: structure, data type, index, relation, etc. (see Pau's talk for a much better explanation ;)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dimensionality:\n",
    "    - 1-D: Series; e.g.\n",
    "        - Solar planets: [Mercury, Venus, Earth, Mars, Jupiter, Saturn, Uranus, Neptune]\n",
    "        - Set of astronomical objects and when they were observed:\n",
    "            [[NGC1952, 2012-05-01],\n",
    "             [NGC224, 2013-01-23],\n",
    "             [NGC5194, 2014-02-13]]\n",
    "    - 2-D: DataFrame; e.g (more business oriented):\n",
    "        - 3 months of sales information for 3 fictitious companies:\n",
    "            sales = [{'account': 'Jones LLC', 'Jan': 150, 'Feb': 200, 'Mar': 140},\n",
    "                     {'account': 'Alpha Co',  'Jan': 200, 'Feb': 210, 'Mar': 215},\n",
    "                     {'account': 'Blue Inc',  'Jan': 50,  'Feb': 90,  'Mar': 95 }]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Index\n",
    "- It is the value (~key) we use as a reference for each element. (Note: It does not have to be unique)\n",
    "\n",
    "- Most of the data contain at least one index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Series definition\n",
    "Series is a one-dimensional labeled array capable of holding any data type\n",
    "\n",
    "The axis labels are collectively referred to as the index\n",
    "\n",
    "This is the basic idea of how to create a Series dataframe:\n",
    "\n",
    "**s = pd.Series(data, index=index)**\n",
    "\n",
    "where data can be:\n",
    "- list\n",
    "- ndarray\n",
    "- python dictionary\n",
    "- scalar\n",
    "and index is a list of axis labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create a Series array from a list\n",
    "If no index is passed, one will be created having values [0, ..., len(data) - 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "solar_planets = ['Mercury','Venus','Earth','Mars','Jupiter','Saturn','Uranus','Neptune']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "splanets = pd.Series(solar_planets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Tips and tricks\n",
    "# To access the Docstring for quick reference on syntax use ? before:\n",
    "#?pd.Series()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "splanets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "splanets.index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create a Series array from a numpy array\n",
    "If data is an ndarray, index must be the same length as data. \n",
    "If no index is passed, one will be created having values [0, ..., len(data) - 1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Not including index:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "s1 = pd.Series(np.random.randn(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s1.index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Including index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "s2 = pd.Series(np.random.randn(5), index=['a', 'b', 'c', 'd', 'e'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s2.index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- From scalar value\n",
    "\n",
    "If data is a scalar value, an index must be provided\n",
    "\n",
    "The value will be repeated to match the length of index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "s3 = pd.Series(5., index=['a', 'b', 'c', 'd', 'e'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s3.index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create a Series array from a python dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "d = {'a' : 0., 'b' : 1., 'c' : 2.}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sd = pd.Series(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DataFrame definition\n",
    "\n",
    "DataFrame is a 2-dimensional labeled data structure with columns of potentially different types (see also [Panel](<https://pandas.pydata.org/pandas-docs/stable/generated/pandas.Panel.html>) - 3-dimensional array).\n",
    "\n",
    "You can think of it **like a spreadsheet or SQL table, or a dict of Series objects**. \n",
    "\n",
    "It is generally the most commonly used pandas object. \n",
    "\n",
    "Like Series, DataFrame accepts many different kinds of input:\n",
    "\n",
    "- Dict of 1D ndarrays, lists, dicts, or Series\n",
    "- 2-D numpy.ndarray\n",
    "- Structured or record ndarray\n",
    "- A Series\n",
    "- Another DataFrame"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### From a list of dictionaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sales = [{'account': 'Jones LLC', 'Jan': 150, 'Feb': 200, 'Mar': 140},\n",
    "                 {'account': 'Alpha Co',  'Jan': 200, 'Feb': 210, 'Mar': 215},\n",
    "                 {'account': 'Blue Inc',  'Jan': 50,  'Feb': 90,  'Mar': 95 }]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = pd.DataFrame(sales)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = df.set_index('account')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### From dict of Series or dicts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "d = {'one' : pd.Series([1., 2., 3.], index=['a', 'b', 'c']),\n",
    "     'two' : pd.Series([1., 2., 3., 4.], index=['a', 'b', 'c', 'd'])}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = pd.DataFrame(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(d, index=['d', 'b', 'a'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### From dict of ndarrays / lists\n",
    "The ndarrays must all be the same length. \n",
    "\n",
    "If an index is passed, it must clearly also be the same length as the arrays. \n",
    "\n",
    "If no index is passed, the result will be range(n), where n is the array length."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "d = {'one' : [1., 2., 3., 4.], 'two' : [4., 3., 2., 1.]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(d, index=['a', 'b', 'c', 'd'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### From structured or record array\n",
    "The ndarrays must all be the same length. If an index is passed, it must clearly also be the same length as the arrays. \n",
    "\n",
    "If no index is passed, the result will be range(n), where n is the array length."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data = np.random.random_sample((5, 5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = pd.DataFrame(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Add index\n",
    "df = pd.DataFrame(data,index = ['a','b','c','d','e'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Add column names\n",
    "df = pd.DataFrame(data, index = ['a','b','c','d','e'], columns = ['ra', 'dec','z_phot','z_true','imag'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "#### From a list of dicts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data2 = [{'a': 1, 'b': 2}, {'a': 5, 'b': 10, 'c': 20}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(data2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(data2, index=['first', 'second'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(data2, columns=['a', 'b'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=exercise1></a>\n",
    "### Exercise 1: Selecting pandas structure\n",
    "Given a few galaxies with some properties ['id', 'ra', 'dec', 'magi'], choose which pandas structure to use and its index:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Few galaxies with some properties: id, ra, dec, magi\n",
    "galaxies = [\n",
    "    {'id' : 1, 'ra' : 4.5, 'dec' : -55.6, 'magi' : 21.3},\n",
    "    {'id' : 3, 'ra' : 23.5, 'dec' : 23.6, 'magi' : 23.3},\n",
    "    {'id' : 25, 'ra' : 22.5, 'dec' : -0.3, 'magi' : 20.8},\n",
    "    {'id' : 17, 'ra' : 33.5, 'dec' : 15.6, 'magi' : 24.3}   \n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load -r 1-19 solutions/06_01_pandas.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=io></a>\n",
    "### I/O\n",
    "### Reading from different sources into a DataFrame\n",
    "- Most of the times any study starts with an **input file** containing some data rather than having a python list or dictionary.\n",
    "\n",
    "- Here we present three different data sources and how to read them: two file formats (**CSV** and **FITS**) and a **database** connection.\n",
    "\n",
    "- **Advanced**: More and more frequently the amount of data to handle is larger and larger (Big Data era) and therefore files are huge. This is why we strongly recommend to always program by chunks (sometimes it is mandatory and also it is not straight forward to implement)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### - From a CSV (Comma Separated Value) file:\n",
    "\n",
    "<https://pandas.pydata.org/pandas-docs/stable/generated/pandas.read_csv.html>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Reading the full catalog at once (if the file is not very large)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- CSV file created using the following query (1341.csv.bz2):\n",
    "\n",
    "```\n",
    "SELECT unique_gal_id, ra_gal, dec_gal, z_cgal, z_cgal_v, lmhalo, (mr_gal - 0.8 * (atan(1.5 * z_cgal)- 0.1489)) AS abs_mag, gr_gal AS color, (des_asahi_full_i_true - 0.8 * (atan(1.5 * z_cgal)- 0.1489)) AS app_mag FROM micecatv2_0_view TABLESAMPLE (BUCKET 1 OUT OF 512)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "filename = '../resources/galaxy_sample.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!head -30 ../resources/galaxy_sample.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- CSV.BZ2 (less storage, slower when reading because of decompression)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "filename_bz2 = '../resources/galaxy_sample.csv.bz2'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!head ../resources/galaxy_sample.csv.bz2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Reading the full catalog at once (if the file is not very large)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Field index name (known a priori from the header or the file description)\n",
    "unique_gal_id_field = 'unique_gal_id'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "galaxy_sample = pd.read_csv(filename, sep=',', index_col = unique_gal_id_field, comment='#', na_values = '\\\\N')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "galaxy_sample.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "galaxy_sample.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- DataFrame.describe:\n",
    "\n",
    "Generates descriptive statistics that summarize the central tendency, dispersion and shape of a dataset’s distribution, excluding NaN values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "galaxy_sample.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "galaxy_sample.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "galaxy_sample_bz2 = pd.read_csv(filename_bz2, sep=',', index_col = unique_gal_id_field, comment='#', na_values = r'\\N')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "galaxy_sample_bz2.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### [FITS file](https://fits.gsfc.nasa.gov/):\n",
    "\n",
    "- Pandas does not read directly FITS files so it is necessary to make some \"convertion\"\n",
    "\n",
    "- We have found 2 different approaches:\n",
    " - [Table](http://docs.astropy.org/en/stable/io/fits/usage/table.html) method from astropy [pyfits](https://pythonhosted.org/pyfits/)\n",
    " - fitsio (see \"Caveats and technicalities\" section below)\n",
    "\n",
    "- Not easy to read it by chunks (see also \"Caveats and technicalities\" section below)\n",
    "\n",
    "- Note: we strongly recommend to use CSV.BZ2!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Using astropy (or pyfits)\n",
    "\n",
    "- This method does not support \"by chunks\" and therefore you have to read it all at once"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from astropy.table import Table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "FITS file created using the same query as the CSV file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "filename = '../resources/galaxy_sample.fits'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#?Table.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data = Table.read(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = data.to_pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = df.set_index('unique_gal_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.values.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### - From Database:\n",
    "\n",
    "https://pandas.pydata.org/pandas-docs/stable/generated/pandas.read_sql.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# For PostgreSQL access\n",
    "from sqlalchemy.engine import create_engine\n",
    "# Text wrapping\n",
    "import textwrap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Database configuration parameters\n",
    "#db_url = '{scheme}://{user}:{password}@{host}/{database}'\n",
    "db_url = 'sqlite:///../resources/pandas.sqlite'\n",
    "\n",
    "sql_sample = textwrap.dedent(\"\"\"\\\n",
    "SELECT *\n",
    "FROM micecatv1\n",
    "WHERE ABS(ra_mag-ra) > 0.05\n",
    "\"\"\")\n",
    "\n",
    "index_col = 'id'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Create database connection\n",
    "engine = create_engine(db_url)\n",
    "df = pd.read_sql(sql_sample, engine,index_col = 'id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Write to csv file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "outfile = '../resources/micecatv1_sample1.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open(outfile, 'w') as f_out:\n",
    "    df.to_csv(f_out,\n",
    "              columns = ['ra', 'dec','ra_mag','dec_mag'],\n",
    "              index=True,\n",
    "              header=True\n",
    "             )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Advanced example: Reading and writing by chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "filename = '../resources/galaxy_sample.csv'\n",
    "outfile = '../resources/galaxy_sample_some_columns.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# chunk size\n",
    "gal_chunk = 100000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Field index name (known a priori from the header or the file description)\n",
    "unique_gal_id_field = 'unique_gal_id'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Opening file with the *with* method\n",
    "\n",
    "- Creating a file object using [read_csv](<https://pandas.pydata.org/pandas-docs/stable/generated/pandas.read_csv.html>) method\n",
    "\n",
    "- Looping by chunks using enumerate in order to also have the chunk number"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(filename, 'r') as galaxy_fd, open (outfile, 'w') as f_out:\n",
    "    galaxy_sample_reader = pd.read_csv(\n",
    "        galaxy_fd, \n",
    "        sep=',', \n",
    "        index_col = unique_gal_id_field, \n",
    "        comment='#', \n",
    "        na_values = '\\\\N', \n",
    "        chunksize=gal_chunk\n",
    "    )\n",
    "    for chunk, block in enumerate(galaxy_sample_reader):\n",
    "        print(chunk)\n",
    "        # In order not to write n chunk times the header (HELP PAU!)\n",
    "        block.to_csv(f_out, \n",
    "            columns = ['ra_gal','dec_gal','z_cgal_v'], \n",
    "            index=True, \n",
    "            header= chunk==0, \n",
    "            mode='a'\n",
    "       )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "block.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "block.tail(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- DataFrame *plot* method (just for curiosity!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DataFrame plot method\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "block['lmhalo'].plot.hist(bins=100, logy = True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=selecting></a>\n",
    "### SELECTING AND SLICING\n",
    "\n",
    "- The idea of this section is to show how to slice and get and set subsets of pandas objects\n",
    "\n",
    "- The basics of indexing are as follows:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| Operation                      | Syntax           | Result        |\n",
    "|--------------------------------|------------------|---------------|\n",
    "| Select column                  | df[column label] | Series        |\n",
    "| Select row by index            | df.loc[index]    | Series        |\n",
    "| Select row by integer location | df.iloc[pos]     | Series        |\n",
    "| Slice rows                     | df[5:10]         | DataFrame     |\n",
    "| Select rows by boolean vector  | df[bool_vec]     | DataFrame     |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Same dataframe as before\n",
    "filename='../resources/galaxy_sample.csv.bz2'\n",
    "galaxy_sample = pd.read_csv(filename, sep=',', index_col = unique_gal_id_field, comment='#', na_values = r'\\N')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "galaxy_sample.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Select a column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "galaxy_sample['ra_gal'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(galaxy_sample['dec_gal'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "galaxy_sample[['ra_gal','dec_gal','lmhalo']].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Select a row by index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "galaxy_sample.loc[28581888]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(galaxy_sample.loc[28581888])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Select a row by integer location"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "galaxy_sample.iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(galaxy_sample.iloc[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Slice rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "galaxy_sample.iloc[3:7]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "galaxy_sample[3:7]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(galaxy_sample.iloc[3:7])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Select rows by boolean vector: \n",
    "\n",
    "The operators are: | for or, & for and, and ~ for not. These must be grouped by using parentheses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Boolean vector\n",
    "(galaxy_sample['ra_gal'] < 45).tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(galaxy_sample['ra_gal'] < 45)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "galaxy_sample[galaxy_sample['ra_gal'] < 45].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# redshift shell\n",
    "galaxy_sample[(galaxy_sample.z_cgal <= 0.2) | (galaxy_sample.z_cgal >= 1.0)].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "galaxy_sample[(galaxy_sample.z_cgal <= 1.0) & (galaxy_sample.index.isin([5670656,13615360,3231232]))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "galaxy_sample[(galaxy_sample['ra_gal'] < 1.) & (galaxy_sample['dec_gal'] < 1.)][['ra_gal','dec_gal']].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Recap:\n",
    "- loc works on labels in the index.\n",
    "- iloc works on the positions in the index (so it only takes integers)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Advanced example: estimate the size of the disk (*disk_length*) for a set of galaxies\n",
    "\n",
    "- In this exercise we are going to use some of the previous examples. \n",
    "- Also we are going to introduce how to add a column and some other concepts\n",
    "\n",
    "    - We split the galaxies into two different populations, Ellipticals and Spirals, depending on the their color and absolute magnitude:\n",
    "        ```\n",
    "         if color - 0.29 + 0.03 * abs_mag < 0 then Spiral\n",
    "         else then Elliptical\n",
    "        ```\n",
    "\n",
    "    - How many galaxies are elliptical or spirals?\n",
    "\n",
    "    - Elliptical galaxies do not have any disk (and therefore disk_length = 0).\n",
    "\n",
    "    - The disk_length for spiral galaxies follows a normal distribution with mean = 0 and sigma = 0.15 (in arcsec). In addition, the minimum disk_length for a spiral galaxy is 1.e-3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "galaxy_sample.tail(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Splitting the galaxies\n",
    "# Boolean mask\n",
    "has_disk_mask = (galaxy_sample['color']-0.29+0.03*galaxy_sample['abs_mag'] < 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "has_disk_mask.tail(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print (len(has_disk_mask))\n",
    "print (type(has_disk_mask))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Counting how many spirals\n",
    "n_spiral = has_disk_mask.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Counting how many ellipticals\n",
    "n_elliptical = ~has_disk_mask.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "galaxy_sample[has_disk_mask].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "galaxy_sample[has_disk_mask]['hubble_type'] = 'Spiral'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# It did not add any column! It was working in a view!\n",
    "galaxy_sample.tail(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# This is the proper way of doing it if one wants to add another column\n",
    "galaxy_sample.loc[has_disk_mask, 'hubble_type'] = 'Spiral'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "galaxy_sample.loc[~has_disk_mask, 'hubble_type'] = 'Elliptical'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "galaxy_sample.tail(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# We can use the numpy where method to do the same:\n",
    "galaxy_sample['color_type'] = np.where(has_disk_mask, 'Blue', 'Red')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "galaxy_sample.tail(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# The proper way would be to use a boolean field\n",
    "galaxy_sample['has_disk'] = has_disk_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "galaxy_sample.tail(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "galaxy_sample.loc[~has_disk_mask, 'disk_length'] = 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "galaxy_sample.loc[has_disk_mask, 'disk_length'] = np.fabs(\n",
    "                np.random.normal(\n",
    "                    0., scale=0.15, size=n_spiral\n",
    "                )\n",
    "            )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DO NOT LOOP THE PANDAS DATAFRAME IN GENERAL!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "galaxy_sample.tail(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Minimum value for disk_length for spirals\n",
    "dl_min = 1.e-4;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "disk_too_small_mask = has_disk_mask & (galaxy_sample['disk_length'] < dl_min)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "disk_too_small_mask.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "galaxy_sample.loc[disk_too_small_mask, 'disk_length'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "galaxy_sample.loc[disk_too_small_mask, 'disk_length'] = dl_min"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "galaxy_sample.loc[disk_too_small_mask, 'disk_length'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "galaxy_sample.tail(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=exercise2></a>\n",
    "### Exercise 2: Estimate another galaxy property\n",
    "\n",
    "- What is the mean value and the standard deviation of the *disk_length* for spiral galaxies (Tip: use the .mean() and .std() methods)\n",
    "\n",
    "- Estimate the bulge_length for elliptical galaxies. The bulge_length depends on the absolute magnitude in the following way:\n",
    "    \n",
    "    bulge_length = exp(-1.145 - 0.269 * (abs_mag - 23.))\n",
    "    \n",
    "- How many galaxies have bulge_lenth > 1.0?  \n",
    "\n",
    "- In our model the maximum bulge_length for an elliptical galaxy is 0.5 arcsec.\n",
    "\n",
    "- What is the mean value and the standard deviation of the *bulge_length* for elliptical galaxies. And for ellipticals with absolute magnitude brighter than -20?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# %load -r 20-102 solutions/06_01_pandas.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=merging></a>\n",
    "### Merge, join, and concatenate\n",
    "\n",
    "<https://pandas.pydata.org/pandas-docs/stable/merging.html>\n",
    "\n",
    "- pandas provides various facilities for easily combining together Series, DataFrame, and Panel objects with various kinds of set logic for the indexes and relational algebra functionality in the case of join / merge-type operations.\n",
    "\n",
    "- *concat* method:\n",
    "```\n",
    "pd.concat(objs, axis=0, join='outer', join_axes=None, ignore_index=False,\n",
    "          keys=None, levels=None, names=None, verify_integrity=False,\n",
    "          copy=True)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df1 = pd.DataFrame(\n",
    "    {'A': ['A0', 'A1', 'A2', 'A3'],\n",
    "     'B': ['B0', 'B1', 'B2', 'B3'],\n",
    "     'C': ['C0', 'C1', 'C2', 'C3'],\n",
    "     'D': ['D0', 'D1', 'D2', 'D3']},\n",
    "    index=[0, 1, 2, 3]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df2 = pd.DataFrame(\n",
    "    {'A': ['A4', 'A5', 'A6', 'A7'],\n",
    "     'B': ['B4', 'B5', 'B6', 'B7'],\n",
    "     'C': ['C4', 'C5', 'C6', 'C7'],\n",
    "     'D': ['D4', 'D5', 'D6', 'D7']},\n",
    "    index=[4, 5, 6, 7]\n",
    ") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df3 = pd.DataFrame(\n",
    "    {'A': ['A8', 'A9', 'A10', 'A11'],\n",
    "     'B': ['B8', 'B9', 'B10', 'B11'],\n",
    "     'C': ['C8', 'C9', 'C10', 'C11'],\n",
    "     'D': ['D8', 'D9', 'D10', 'D11']},\n",
    "    index=[8, 9, 10, 11]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "frames = [df1, df2, df3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = pd.concat(frames)\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Multiindex\n",
    "result = pd.concat(frames, keys=['x', 'y','z'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result.loc['y']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df4 = pd.DataFrame(\n",
    "    {'B': ['B2', 'B3', 'B6', 'B7'],\n",
    "     'D': ['D2', 'D3', 'D6', 'D7'],\n",
    "     'F': ['F2', 'F3', 'F6', 'F7']},\n",
    "    index=[2, 3, 6, 7]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = pd.concat([df1, df4])\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = pd.concat([df1, df4], axis=1)\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = pd.concat([df1, df4], axis=1, join='inner')\n",
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Using *append* method:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = df1.append(df2)\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = df1.append(df4)\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = pd.concat([df1,df4])\n",
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Note: Unlike list.append method, which appends to the original list and returns nothing, append here does not modify df1 and returns its copy with df2 appended."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = pd.concat([df1,df4], ignore_index=True)\n",
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- This is also a valid argument to DataFrame.append:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = df1.append(df4, ignore_index = True)\n",
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Mixing dimensions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s1 = pd.Series(['X0', 'X1', 'X2', 'X3'], name='X')\n",
    "s1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = pd.concat([s1,df1])\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = pd.concat([df1,s1], axis = 1)\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "s2 = pd.Series(['_0', '_1', '_2', '_3'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = pd.concat([df1,s2,s2,s2], axis = 1)\n",
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "<a id=exercise3></a>\n",
    "### Exercise 3: Generate a random catalog using concat method\n",
    "\n",
    "- In this exercise we will use the concat method and show a basic example of multiIndex.\n",
    "\n",
    "- Given a subset of a few galaxies with the following properties ['halo_id', 'gal_id' ,'ra', 'dec', 'z', 'abs_mag'], create a random catalog with 50 times more galaxies than the subset keeping the properties of the galaxies but placing them randomly in the first octant of the sky. \n",
    "\n",
    "- The index of each galaxy is given by the tuple [halo_id, gal_id]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data =  [\n",
    "    # halo_id, gal_id, ra, dec, z, abs_mag'\n",
    "    [1, 1, 21.5, 30.1, 0.21, -21.2],\n",
    "    [1, 2, 21.6, 29.0, 0.21, -18.3],\n",
    "    [1, 3, 21.4, 30.0, 0.21, -18.5],\n",
    "    [2, 1, 45.0, 45.0, 0.42, -20.4],\n",
    "    [3, 1, 25.0, 33.1, 0.61, -21.2],\n",
    "    [3, 2, 25.1, 33.2, 0.61, -20.3]\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# %load -r 103-145 solutions/06_01_pandas.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Merge method: Database-style DataFrame joining/merging:\n",
    "\n",
    "- pandas has full-featured, high performance in-memory join operations idiomatically very similar to relational databases like SQL. These methods perform significantly better (in some cases well over an order of magnitude better) than other open source implementations (like base::merge.data.frame in R). The reason for this is careful algorithmic design and internal layout of the data in DataFrame\n",
    "\n",
    "- See the [cookbook](https://pandas.pydata.org/pandas-docs/stable/cookbook.html) for some advanced strategies\n",
    "\n",
    "- Users who are familiar with SQL but new to pandas might be interested in a [comparison with SQL](https://pandas.pydata.org/pandas-docs/stable/comparison_with_sql.html#compare-with-sql-join)\n",
    "\n",
    "```\n",
    "pd.merge(left, right, how='inner', on=None, left_on=None, right_on=None,\n",
    "         left_index=False, right_index=False, sort=True,\n",
    "         suffixes=('_x', '_y'), copy=True, indicator=False)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example: Merging dataframes using the merge method (thanks Nadia!)\n",
    "\n",
    "- Goal: build a dataframe merging 2 different dataframes with complementary information, through the relation given by a third dataframe.\n",
    "\n",
    "    - df_stars contains information of stars magnitudes per sdss_star_id and per *filter*:\n",
    "        - ['sdss_star_id', 'filter', 'expected_mag', 'expected_mag_err']\n",
    "        - Note, the file is \"somehow\" corrupted and entries are duplicate several times\n",
    "        - Unique entries are characterized by *sdss_star_id* and *filter*\n",
    "    - df_spectra contains information of star *flux* per *band* (== *filter*) and per *spec_id* (!= *sdss_star_id*):\n",
    "        - ['spec_id', 'band', 'flux', 'flux_err']\n",
    "        - Unique entries are characterized by *spec_id* and *band*\n",
    "    - df_spec_IDs allows to make the correspondence between *sdss_star_id* (== *objID*) and *spec_id* (== *specObjID*):\n",
    "        - ['objID', 'specObjID']\n",
    "        - Unique entries are characterized by *objID*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "star_filename = '../resources/df_star.ssv'\n",
    "spectra_filename = '../resources/df_spectra.ssv'\n",
    "starid_specid_filename = '../resources/df_starid_specid.ssv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_spectra = pd.read_csv(spectra_filename, index_col=['spec_id', 'band'], sep = ' ')\n",
    "df_spectra.head(41)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_starid_specid = pd.read_csv(starid_specid_filename, sep=' ')\n",
    "df_starid_specid.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Given that the file is somehow corrupted we open it without defining any index\n",
    "df_star = pd.read_csv(star_filename, sep=' ')\n",
    "df_star.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_star[(df_star['sdss_star_id'] == 1237653665258930303) & (df_star['filter'] == 'NB455')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Drop duplicates:\n",
    "df_star.drop_duplicates(subset = ['sdss_star_id', 'filter'], inplace= True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_star[(df_star['sdss_star_id'] == 1237653665258930303) & (df_star['filter'] == 'NB455')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_starid_specid.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "- We are going to unset the index and rename the columns in order to use the \"on\" argument:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_spectra.reset_index(inplace = True)\n",
    "df_spectra.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_spectra.rename(columns={'band': 'filter'}, inplace = True)\n",
    "df_spectra.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_starid_specid.rename(columns={'objID':'sdss_star_id', 'specObjID':'spec_id'}, inplace = True)\n",
    "df_starid_specid.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "- Now we have everything ready to make the JOINs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_star_merged = pd.merge(df_star, df_starid_specid, on='sdss_star_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_star_merged.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_star_merged = pd.merge(df_star_merged, df_spectra, on=['spec_id','filter'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_star_merged.head(40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_star_merged.set_index(['sdss_star_id', 'filter'], inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_star_merged.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Each element has been observed in how many bands?\n",
    "count_bands = df_star_merged.groupby(level=0)['flux'].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_bands.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_star_merged.groupby(level=1)['flux_err'].mean().head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=functions></a>\n",
    "### More functions\n",
    "- Looping a dataframe (iterrows):\n",
    "\n",
    "<https://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.iterrows.html>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- sort method:\n",
    "\n",
    "<https://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.sort_values.html>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "- sample method:\n",
    "\n",
    "<https://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.sample.html>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Reshape dataframes (pivot, stack, unstack):\n",
    "\n",
    "<http://nikgrozev.com/2015/07/01/reshaping-in-pandas-pivot-pivot-table-stack-and-unstack-explained-with-pictures/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Data cleaning:\n",
    "    \n",
    "    - check for missing values (isnull): <https://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.isnull.html>\n",
    "    - drop missing values (dropna): <https://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.dropna.html>\n",
    "    - fill the missing values with other values (fillna): <https://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.fillna.html>\n",
    "    - replace values with different values (replace): <https://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.replace.html>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Some general ideas to get home:\n",
    "\n",
    "- Do not loop a dataframe!\n",
    "\n",
    "- Try to work by chunks; create functions that work with chunks\n",
    "\n",
    "- Work with standard formats and \"already implemented\" functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=caveats></a>\n",
    "### Caveats and technicalities"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [Floating point limitations](<https://docs.python.org/2/tutorial/floatingpoint.html>):\n",
    "\n",
    "- Be careful with exact comparisons!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# e.g.: the decimal value 0.1 cannot be represented exactly as a base 2 fraction\n",
    "(0.1 + 0.2) == 0.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(0.1 + 0.2) - 0.3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### FITS files\n",
    "\n",
    "- [fitsio](<https://pypi.python.org/pypi/fitsio/>)\n",
    "\n",
    "- And working by chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import fitsio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "filename = '../resources/galaxy_sample.fits'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fits=fitsio.FITS(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = fits[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of rows\n",
    "data.get_nrows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# chunk size\n",
    "gal_chunk = 300000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# e.g.to create the ranges!\n",
    "import math\n",
    "niter = int(math.ceil(data.get_nrows() / float(gal_chunk)))\n",
    "\n",
    "for i in range(niter):\n",
    "    s = i*gal_chunk\n",
    "    f = min((i+1)*gal_chunk, data.get_nrows())\n",
    "    chunk = data[s:f]\n",
    "    print (i)\n",
    "    print (type(chunk))\n",
    "    print (chunk.dtype)\n",
    "    df_chunk = pd.DataFrame(chunk)\n",
    "    print (type(df_chunk))\n",
    "    print (df_chunk.dtypes)\n",
    "    df_chunk = df_chunk.set_index('unique_gal_id')\n",
    "    print (df_chunk.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### [.values](https://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.values.html) DataFrame attribute \n",
    "\n",
    "- Some scipy functions do not allow to use pandas dataframe as arguments and therefore it is useful to use the values atribute, which is the numpy representation of NDFrame\n",
    "\n",
    "- The dtype will be a lower-common-denominator dtype (implicit upcasting); that is to say if the dtypes (even of numeric types) are mixed, the one that accommodates all will be chosen. Use this with care if you are not dealing with the blocks."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### View vs. Copy\n",
    "\n",
    "<https://pandas.pydata.org/pandas-docs/stable/indexing.html#returning-a-view-versus-a-copy>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "#### Wrong input example:\n",
    "- .dat\n",
    "\n",
    "- Look at the file using e.g. *head* bash command\n",
    "\n",
    "- Note that there are more than one space, and if you do *tail filename*, different number of \"spaces\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "bad_filename = '../resources/steps.flagship.dat'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_bad = pd.read_csv(bad_filename)\n",
    "df_bad.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_bad =  pd.read_csv(bad_filename, sep = ' ')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Necessary to \"modify\" the file in order to convert it into a standard csv file, e.g.:\n",
    "\n",
    "```\n",
    "cat steps.flagship.dat | tr -s \" \" | sed 's/^ *//g' > steps.flagship.ssv\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "filename = '../resources/steps.flagship.ssv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "columns = ['step_num', 'r_min', 'r_max', 'r_med', 'a_med', 'z_med']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(filename, sep = ' ', header = None, names = columns, index_col = 'step_num')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
