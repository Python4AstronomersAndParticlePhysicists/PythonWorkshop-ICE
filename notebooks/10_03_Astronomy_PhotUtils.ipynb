{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "![astropylogo](../resources/photutils_logo.svg)\n",
    "\n",
    "## Photometry with Photutils"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Photutils is an affiliated package of Astropy to provide tools for detecting and performing photometry of astronomical sources.\n",
    "\n",
    "It contains tools for:\n",
    "\n",
    "* **Background Estimation (photutils.background)**\n",
    "* **Source Detection (photutils.detection)**\n",
    "* Grouping Algorithms\n",
    "* **Aperture Photometry (photutils.aperture)**\n",
    "* PSF Photometry (photutils.psf)\n",
    "* PSF Matching (photutils.psf.matching)\n",
    "* Image Segmentation (photutils.segmentation)\n",
    "* Centroids (photutils.centroids)\n",
    "* Morphological Properties (photutils.morphology)\n",
    "* Geometry Functions (photutils.geometry)\n",
    "* Datasets (photutils.datasets)\n",
    "* Utility Functions (photutils.utils)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn\n",
    "from astropy.io import fits\n",
    "from astropy import units as u\n",
    "from astropy.coordinates import SkyCoord\n",
    "plt.rcParams['figure.figsize'] = (12, 8)\n",
    "plt.rcParams['font.size'] = 14\n",
    "plt.rcParams['lines.linewidth'] = 2\n",
    "plt.rcParams['xtick.labelsize'] = 13\n",
    "plt.rcParams['ytick.labelsize'] = 13\n",
    "plt.rcParams['axes.titlesize'] = 14\n",
    "plt.rcParams['legend.fontsize'] = 13"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we will be using the image visualization several times, let's make a function that makes our code cleaner:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from astropy.visualization import ZScaleInterval\n",
    "\n",
    "def my_python_ds9(data):\n",
    "    norm = ZScaleInterval()\n",
    "    vmin, vmax = norm.get_limits(data)\n",
    "    plt.imshow(data, vmin=vmin, vmax=vmax, interpolation='none', origin='lower')\n",
    "    plt.colorbar()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before performing any photometry we need to have a first guess of the image background properties. For this section we will use a simpler optical image from the Sloan Digital Sky Survey (SDSS). This image contains the Spindle Galaxy, also known as Messier 102 or NGC 5866."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sdss_g_hdu_list = fits.open('../resources/sdss_g.fits')\n",
    "sdss_g_hdu_list.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_python_ds9(sdss_g_hdu_list[0].data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(np.power(sdss_g_hdu_list[0].data[580:730, 500:750], 0.5), cmap='inferno', origin='lower')\n",
    "plt.grid('off')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's get the basic statistics of it. For that we will need to remove the sources using a sigma clipping routine:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from astropy.stats import sigma_clipped_stats\n",
    "\n",
    "mean, median, std = sigma_clipped_stats(sdss_g_hdu_list[0].data, sigma=3.0, iters=5)    \n",
    "print((mean, median, std))    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will need also the pixel scale that we can retrieve from the WCS:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from astropy import wcs\n",
    "\n",
    "sdss_g_image_wcs = wcs.WCS(sdss_g_hdu_list[0].header)\n",
    "sdss_pixelscale = np.mean(wcs.utils.proj_plane_pixel_scales(sdss_g_image_wcs) * u.degree).to('arcsec')\n",
    "sdss_pixelscale"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Object detection\n",
    "\n",
    "To detect the sources inside a astronomical image PhotUtils provides DAO Phot implementations to detect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from photutils import DAOStarFinder\n",
    "sigma_detection = 5.0\n",
    "daofind = DAOStarFinder(fwhm=1.5 * u.arcsec / sdss_pixelscale, threshold=sigma_detection*std)    \n",
    "sources = daofind(sdss_g_hdu_list[0].data - median)    \n",
    "print(sources)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_python_ds9(sdss_g_hdu_list[0].data)\n",
    "\n",
    "plt.scatter(sources['xcentroid'], sources['ycentroid'], alpha=0.5, color='limegreen')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PSF Modelling\n",
    "\n",
    "We assumed that the image had a typical value of 1.5\" per pixel. But we can make a more accurate estimation by fitting the pixels to a moffat profile around a detected star."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, let's select the source we want to use for PSF modelling:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "isource = sources[50]\n",
    "\n",
    "# High SN - 50\n",
    "# Low SN - 33\n",
    "# Non-uniform background - 78\n",
    "\n",
    "print (\"x pos: \" + str(isource['xcentroid']))\n",
    "print (\"y pos: \" + str(isource['ycentroid']))\n",
    "\n",
    "stamp_radius = 50\n",
    "my_python_ds9(sdss_g_hdu_list[0].data[int(isource['ycentroid'] - stamp_radius):\n",
    "                                      int(isource['ycentroid'] + stamp_radius), \n",
    "                                      int(isource['xcentroid'] - stamp_radius): \n",
    "                                      int(isource['xcentroid'] + stamp_radius)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we intend to find the profile of the source, we need to remove the possible sky background that lies behind:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Median bkg subtracted image\n",
    "bkg_subtracted_image = sdss_g_hdu_list[0].data - median\n",
    "\n",
    "# 2D background subtracted - For later\n",
    "#bkg_subtracted_image = sdss_g_hdu_list[0].data - bkg.background"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To simplify the problem, we turn the 2D profile into a 1D distance array from the center of each pixel to the centroid of the source estimated by DAO Phot:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "flux_counts = []\n",
    "pixel_distance = []\n",
    "\n",
    "x_cen = int(isource['xcentroid'])\n",
    "y_cen = int(isource['ycentroid'])\n",
    "\n",
    "# Pixels around detection loop\n",
    "analysis_radius = 10\n",
    "for x in range(x_cen - analysis_radius, x_cen + analysis_radius):\n",
    "    for y in range(y_cen - analysis_radius, y_cen + analysis_radius):\n",
    "        flux_counts.append(((bkg_subtracted_image[y][x]) / isource['peak']))\n",
    "        pixel_distance.append(np.linalg.norm((isource['xcentroid'] - x, isource['ycentroid'] - y)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we present two possible models that can fit the PSF distribution. A Gaussian and a Moffat profile:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from astropy.modeling import models, fitting\n",
    "\n",
    "model = 'moffat'\n",
    "\n",
    "if model == 'gaussian':\n",
    "    # Fit the data using a Gaussian\n",
    "    fwhm_best_guess = 1.5\n",
    "    model_init = models.Gaussian1D(amplitude=1.0, mean=0, stddev=fwhm_best_guess)\n",
    "elif model == 'moffat':\n",
    "    # Fit the data using a Moffat\n",
    "    model_init = models.Moffat1D(amplitude=1.0, x_0=0, gamma=2., alpha=3.5)\n",
    "else:\n",
    "    raise Exception(\"Unknown model type: %s. Must be gaussian or moffat.\" % model)\n",
    "\n",
    "fitter = fitting.SimplexLSQFitter()\n",
    "fitted_model = fitter(model_init, pixel_distance, flux_counts)\n",
    "\n",
    "print (\"Fit value:\",  fitter.fit_info['final_func_val'])\n",
    "print (\"SN:\", isource['flux'] * sigma_detection)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once fitted the models, we need to convert from the parameters to the actual FWHM estimate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FHWM conversion\n",
    "if model == 'gaussian':\n",
    "    iFWHM = 2.355 * fitted_model.stddev * sdss_pixelscale.value\n",
    "elif model == 'moffat':\n",
    "    iFWHM = fitted_model.gamma * 2 * np.sqrt(2 ** (1. / fitted_model.alpha) - 1) * sdss_pixelscale.value\n",
    "else:\n",
    "    raise Exception(\"Unknown model type: %s. Must be gaussian or moffat.\" % model)\n",
    "\n",
    "print (\"FWHM estimated: \", iFWHM)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can finally plot and see how the model traces the pixel values traces our fitted model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check fitting\n",
    "if fitter.fit_info['final_func_val'] < 5.0:\n",
    "    color = 'green'\n",
    "else:\n",
    "    color = 'red'\n",
    "    \n",
    "# Plot the data with the best-fit model\n",
    "plt.figure()\n",
    "plt.plot(pixel_distance, flux_counts, 'ko')\n",
    "rx = np.linspace(0, int(max(pixel_distance)), int(max(pixel_distance)) * 10)\n",
    "plt.plot(rx,\n",
    "         fitted_model(rx),\n",
    "         color=color,\n",
    "         lw=3.0,\n",
    "         label='SN: %.2f, Fit: %.2f, FWHM: %.2f\"' % (isource['flux'] * sigma_detection,\n",
    "                                                       fitter.fit_info['final_func_val'],\n",
    "                                                       iFWHM))\n",
    "plt.xlabel('Distance (pixels)')\n",
    "plt.ylabel('Normalized flux (ADU)')\n",
    "plt.title('%s profile fit' % model)\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Background modelling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we have seen in the case with non-uniform background, the constant median can be insuficient. Here we produce a 2D model of the background that can be subtracted from the original image to improve the modelling of the stars close to a very large extended source (or when the backrgound is not flat for any other reason)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from photutils import Background2D, SigmaClip, MedianBackground\n",
    "sigma_clip = SigmaClip(sigma=3., iters=10)\n",
    "bkg_estimator = MedianBackground()\n",
    "bkg = Background2D(data=sdss_g_hdu_list[0].data, \n",
    "                   box_size=(100, 100), \n",
    "                   filter_size=(3, 3),\n",
    "                   sigma_clip=sigma_clip, \n",
    "                   bkg_estimator=bkg_estimator)\n",
    "my_python_ds9(bkg.background)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Now let's go back to where the background was subtracted to verify the difference."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Aperture photometry"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will work with the simple circular apertures. First we need to set the size we want and create the aperture objects:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from photutils import CircularAperture\n",
    "\n",
    "aperture_radius = 5.0\n",
    "\n",
    "positions = (sources['xcentroid'], sources['ycentroid'])\n",
    "apertures = CircularAperture(positions, r=aperture_radius)\n",
    "\n",
    "my_python_ds9(sdss_g_hdu_list[0].data[0:400, 0:400])\n",
    "apertures.plot(color='limegreen', lw=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Global Background subtraction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we only want the flux from the sources we are interested in, we need to remove the contribution from the background. The simplest way is to remove the median value constant of the sigma clipped image that we calculated before to the entire array:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from photutils import aperture_photometry\n",
    "\n",
    "bkg_subtracted_image = sdss_g_hdu_list[0].data - median\n",
    "phot_table_global_bkg = aperture_photometry(bkg_subtracted_image, apertures)\n",
    "print (phot_table_global_bkg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Local Background subtraction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We could also remove the 2D background model that we calculated before, but it is usually more precise to create an annulus around the source we are interested in, and estimate the background level there."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from photutils import CircularAnnulus\n",
    "\n",
    "r_in = 10\n",
    "r_out = 15\n",
    "\n",
    "annulus_apertures = CircularAnnulus(positions, r_in=r_in, r_out=r_out)\n",
    "\n",
    "my_python_ds9(sdss_g_hdu_list[0].data[0:400, 0:400])\n",
    "apertures.plot(color='limegreen', lw=2)\n",
    "annulus_apertures.plot(color='purple', lw=2, alpha=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The circular apertures and the annulus can be joined for a common photometry processing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "apers = [apertures, annulus_apertures]\n",
    "phot_table_local_bkg = aperture_photometry(sdss_g_hdu_list[0].data, apers)\n",
    "print(phot_table_local_bkg)    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we use the aperture_sum_1 to estimate the level of background around the source. We need to know the area of the annulus for this estimation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "bkg_mean = phot_table_local_bkg['aperture_sum_1'] / annulus_apertures.area()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And finally we can remove the background estimation to all pixels in the aperture:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bkg_sum = bkg_mean * apertures.area()\n",
    "final_sum = phot_table_local_bkg['aperture_sum_0'] - bkg_sum\n",
    "phot_table_local_bkg['residual_aperture_sum'] = final_sum\n",
    "print(phot_table_local_bkg['residual_aperture_sum'])    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this comparison we see that many sources have the same flux with both methods but a significant amount of sources (the ones in the galaxy halo) have significantly more flux in the global subtraction method, as the flux from M102 is added to the one of the stars."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(phot_table_local_bkg['residual_aperture_sum'], phot_table_global_bkg['aperture_sum'])\n",
    "plt.xlim(0,100)\n",
    "plt.ylim(0,100)\n",
    "plt.xlabel('Local background')\n",
    "plt.ylabel('Global background')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's make a plot to verify this! Astropy qtables work similarly to Pandas, so we can make iloc searches."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <span style=\"color:blue\">Exercise PhotUtils:</span> Identify problematic sources\n",
    "Locate which sources differ their flux in more than 50% between the measurement with local and global background estimation. Plot the results on the image.\n",
    "\n",
    "TIP: Using the \"pandas-like\" tools can facilitate the selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load -r 43-52 solutions/10_Astronomy.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Accessing to annulus pixels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "By default when calling aperture_photometry, we only receive the sum of pixels and therefore we can only access to the mean of the pixel values inside an aperture. To properly measure the local background, we would need to get the median of the pixels in the annulus and preferably, perform a sigma clipping over the values.\n",
    "\n",
    "Recently photutils enabled masks so we can actually do that!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Flat annulus - 11\n",
    "# Source in annulus - 12\n",
    "\n",
    "source_num = 12\n",
    "\n",
    "x = phot_table_local_bkg[source_num]['xcenter'].value\n",
    "y = phot_table_local_bkg[source_num]['ycenter'].value\n",
    "\n",
    "stamp_radius = 20\n",
    "my_python_ds9(sdss_g_hdu_list[0].data[int(y - stamp_radius):\n",
    "                                      int(y + stamp_radius), \n",
    "                                      int(x - stamp_radius): \n",
    "                                      int(x + stamp_radius)])\n",
    "plt.grid('off')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can access to the annulus mask:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create annulus mask\n",
    "annulus_apertures = CircularAnnulus((x, y), r_in=r_in, r_out=r_out)\n",
    "masks = annulus_apertures.to_mask(method='center')\n",
    "m0 = masks[0]\n",
    "\n",
    "plt.imshow(m0)\n",
    "plt.grid('off')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And apply it to the data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cut to data\n",
    "cutout_data = m0.apply(sdss_g_hdu_list[0].data)\n",
    "\n",
    "plt.imshow(cutout_data)\n",
    "plt.grid('off')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have access to the pixels, we can perform the median and compare to the mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "annulus_array = cutout_data[cutout_data != 0]\n",
    "\n",
    "# Apply statistics to masked data\n",
    "mean = np.mean(annulus_array)\n",
    "median = np.median(annulus_array)\n",
    "std = np.std(annulus_array)\n",
    "print (mean, median, std)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And even sigma-clip the sources that may appear on top of the background. This creates a numpy.masked array:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from astropy.stats import sigma_clip\n",
    "\n",
    "clip_annulus_array = sigma_clip(annulus_array, sigma=3, iters=2)\n",
    "\n",
    "mean_clipped = np.ma.mean(clip_annulus_array)\n",
    "median_clipped = np.ma.median(clip_annulus_array)\n",
    "std_clipped = np.ma.std(clip_annulus_array)\n",
    "print (mean_clipped, median_clipped, std_clipped)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <span style=\"color:blue\">Exercise PhotUtils 2:</span> Estimate aperture error\n",
    "Compute what would be the measurement error for the last aperture (the one with sigma clipping)\n",
    "\n",
    "$$\n",
    "\\sigma^2_{F} = \\sum_i{\\sigma^2_{i}+F/g}\n",
    "$$\n",
    "\n",
    "TIP: Gain is the exposure time when pixels are in e/s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load -r 56-61 solutions/10_Astronomy.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this link you can find details on how to estimate the error:\n",
    "http://photutils.readthedocs.io/en/stable/photutils/aperture.html#error-estimation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Matching catalogues"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**astropy.coordinates** contains commonly-used tools for comparing or matching coordinate objects. It supports leverages the coordinate framework to make it straightforward to find the closest coordinates in a catalog to a desired set of other coordinates. \n",
    "\n",
    "Let's do a new catalogue with the SDSS r band image on the same location in the sky"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sdss_r_hdu_list = fits.open('../resources/sdss_r.fits')\n",
    "sdss_r_hdu_list.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we plot the previous apertures in the sky, we realize that there is a slight offset (either due to pointing inaccuracy or dithering observarions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_python_ds9(sdss_r_hdu_list[0].data[0:200, 0:300])\n",
    "apertures.plot(color='limegreen', lw=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to make a r band catalogue, we follow the same process as before \n",
    "\n",
    "[   don't replicate code like we do here... you should create a function or Scott will get mad!!   ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print (\"Image statistics...\")\n",
    "mean_r, median_r, std_r = sigma_clipped_stats(sdss_r_hdu_list[0].data, sigma=3.0, iters=5)    \n",
    "\n",
    "print (\"Source detection...\")\n",
    "sources_r = daofind(sdss_r_hdu_list[0].data - median_r)    \n",
    "\n",
    "print (\"Aperture definition...\")\n",
    "positions_r = (sources_r['xcentroid'], sources_r['ycentroid'])\n",
    "apertures_r = CircularAperture(positions_r, r=aperture_radius)\n",
    "annulus_apertures_r = CircularAnnulus(positions_r, r_in=10, r_out=15)\n",
    "\n",
    "print (\"Photometry calculation...\")\n",
    "apers_r = [apertures_r, annulus_apertures_r]\n",
    "phot_table_local_bkg_r = aperture_photometry(sdss_r_hdu_list[0].data, apers_r)\n",
    "bkg_mean_r = phot_table_local_bkg_r['aperture_sum_1'] / annulus_apertures_r.area()\n",
    "bkg_sum_r = bkg_mean_r * apertures_r.area()\n",
    "final_sum_r = phot_table_local_bkg_r['aperture_sum_0'] - bkg_sum_r\n",
    "phot_table_local_bkg_r['residual_aperture_sum'] = final_sum_r\n",
    "\n",
    "print (\"..ready!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In addition we se that more/different objects have been detected due to the different spectral emission of the sources"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_python_ds9(sdss_r_hdu_list[0].data[0:200, 0:300])\n",
    "apertures.plot(color='limegreen', lw=2)\n",
    "apertures_r.plot(color='red', lw=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we create the two catalogues in sky coordinates using the WCS information as matching needs to be happen the same frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "origin = 0\n",
    "### g band catalogue ###\n",
    "# Create wcs object\n",
    "sdss_g_image_wcs = wcs.WCS(sdss_g_hdu_list[0].header)\n",
    "\n",
    "# Pixels to Sky\n",
    "lon_g, lat_g = sdss_g_image_wcs.all_pix2world(phot_table_local_bkg['xcenter'], \n",
    "                                              phot_table_local_bkg['ycenter'], \n",
    "                                              origin)\n",
    "cat_g = SkyCoord(ra=lon_g*u.degree, dec=lat_g*u.degree)  \n",
    "\n",
    "\n",
    "### r band catalogue ###\n",
    "# Create wcs object\n",
    "sdss_r_image_wcs = wcs.WCS(sdss_r_hdu_list[0].header)\n",
    "\n",
    "# Pixels to Sky\n",
    "lon_r, lat_r = sdss_r_image_wcs.all_pix2world(phot_table_local_bkg_r['xcenter'], \n",
    "                                          phot_table_local_bkg_r['ycenter'], \n",
    "                                          origin)\n",
    "cat_r = SkyCoord(ra=lon_r*u.degree, dec=lat_r*u.degree)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Closest catalogue matching\n",
    "The following function performs the matching between the two catalogues, and returns what is the closest \"r\" source to each of the \"g\" sources. Therefore the resulting arrays contain the same number of indices than the catalogue \"g\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "id_r, d2d, d3d = cat_g.match_to_catalog_sky(cat_r)\n",
    "\n",
    "print (len(id_r))\n",
    "\n",
    "hist_data = plt.hist(d2d.to('arcsec'), bins=100)\n",
    "plt.xlabel('distance (arcsec)')\n",
    "plt.ylabel('counts')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comparing the fluxes, some matches show a very large difference, due to source mismatch and not due to color."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(phot_table_local_bkg['residual_aperture_sum'], phot_table_local_bkg_r[id_r]['residual_aperture_sum'])\n",
    "plt.xlabel('g flux')\n",
    "plt.ylabel('r flux')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Search around coordinates matching\n",
    "The following function performs the matching between the two catalogues, returning only those sources that match within certain tolerance in the sky. Therefore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "id_r_around, id_g_around, d2d_around, d3d_around = cat_g.search_around_sky(cat_r, 1*u.arcsec)  \n",
    "\n",
    "print (len(id_r_around))\n",
    "\n",
    "hist_data = plt.hist(d2d_around.to('arcsec'), bins=100)\n",
    "plt.xlabel('distance (arcsec)')\n",
    "plt.ylabel('counts')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can see how the biggest outliers have disappeared, remaining only the difference in flux due to color."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(phot_table_local_bkg[id_g_around]['residual_aperture_sum'], phot_table_local_bkg_r[id_r_around]['residual_aperture_sum'])\n",
    "plt.xlabel('g flux')\n",
    "plt.ylabel('r flux')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### From fluxes to magnitudes (in SDSS)\n",
    "The images we use are already calibrated in photometry, and the units used are nanomaggies. Therefore\n",
    "\n",
    "m = [22.5 mag] – 2.5 log10 f.\n",
    "\n",
    "http://www.sdss.org/dr12/algorithms/magnitudes/#nmgy "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def to_sdss_mag(fluxes):\n",
    "    return 22.5 - np.log(fluxes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Checking relation between measured flux and calibrated magnitude"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mags_g = to_sdss_mag(phot_table_local_bkg['residual_aperture_sum'])\n",
    "plt.scatter(mags_g, phot_table_local_bkg['residual_aperture_sum'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Matching to an external catalogue"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the SDSS catalogue with astroquery that overlaps the image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from astroquery.sdss import SDSS\n",
    "from astropy import coordinates as coords\n",
    "\n",
    "region = np.mean(sdss_r_image_wcs.calc_footprint(), axis=0)\n",
    "c = SkyCoord(region[0] * u.degree, region[1] * u.degree, frame='icrs')\n",
    "\n",
    "sdss_query = SDSS.query_region(c,\n",
    "                               spectro=False,\n",
    "                               radius=20*u.arcmin,\n",
    "                               photoobj_fields=['ra','dec','u','g','r','i','z'])\n",
    "print(sdss_query)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Checking the catalogue: Color - Color plot\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib.colors import LogNorm\n",
    "\n",
    "plt.hist2d(sdss_query['g'] - sdss_query['r'], \n",
    "           sdss_query['r'] - sdss_query['i'],\n",
    "           range=[(-0.5,2), (-0.5,2)], \n",
    "           bins=50, \n",
    "           norm=LogNorm(),\n",
    "          cmap='hot')\n",
    "plt.colorbar()\n",
    "plt.xlabel('g-r')\n",
    "plt.ylabel('r-i')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally we can check that calibrated photometry matches within some margin (probably due to different extraction method - Aperture vs Model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "cat_sdss_query = SkyCoord(ra=sdss_query['ra'] * u.degree, dec=sdss_query['dec'] * u.degree)  \n",
    "\n",
    "id_query_around, id_g_around, d2d_around, d3d_around = cat_g.search_around_sky(cat_sdss_query, 0.5*u.arcsec)  \n",
    "\n",
    "print (len(id_query_around))\n",
    "\n",
    "plt.scatter(sdss_query[id_query_around]['g'], to_sdss_mag(phot_table_local_bkg[id_g_around]['residual_aperture_sum']))\n",
    "plt.xlim(15, 25)\n",
    "plt.ylim(15,25)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
